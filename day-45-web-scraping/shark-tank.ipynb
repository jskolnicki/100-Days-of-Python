{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def extract_endpoint(url):\n",
    "    url = url.rstrip('/')\n",
    "    url_parts = url.split('/')\n",
    "    return f\"{url_parts[-1]}.html\"\n",
    "\n",
    "def add_page_source(url):\n",
    "    url=f\"view-source:{url}\"\n",
    "    return url\n",
    "\n",
    "\n",
    "\n",
    "with open(\"shark-tank.html\") as file:\n",
    "    contents = file.read()\n",
    "\n",
    "soup = BeautifulSoup(contents,'html.parser')\n",
    "\n",
    "all_div_tags = soup.find_all(name='div', class_='list-table-container')\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for season in all_div_tags:\n",
    "    season_number = int(season.get(\"data-number\"))\n",
    "    for episode in season.find_all(name='tr'):\n",
    "        episode_number = int(episode.find(name='td').text)\n",
    "        for show in episode.find_all(\"a\"):\n",
    "            company = html.unescape(show.getText())\n",
    "            link = show.get(\"href\")\n",
    "            endpoint = extract_endpoint(link)\n",
    "            page_source = add_page_source(link)\n",
    "            df_list.append((season_number,episode_number,company,link,endpoint,page_source))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(df_list, columns=['Season','Episode','Company','Link',\"Endpoint\",\"Page Source\"])\n",
    "df = df.sort_values(by=[\"Season\",\"Episode\"])\n",
    "\n",
    "df.to_csv(\"D:/Downloads/shark-tank.csv\",index=False)\n",
    "\n",
    "###################################################################################\n",
    "full_df_list = []\n",
    "for index,pitch in df.head(1).iterrows():\n",
    "    air_date, business_pitch, entrepreneur, ask_money, ask_equity, deal, shark, business_status, valuation, website, summary = (None, None, None, None, None, None, None, None, None, None, None)\n",
    "\n",
    "    # Get the current notebook directory (where the .ipynb file is located)\n",
    "    notebook_dir = Path.cwd()\n",
    "    file_path = notebook_dir / f\"episode-html/{pitch.Endpoint}\"\n",
    "\n",
    "    # Open the file\n",
    "    with open(file_path) as file:\n",
    "        contents = file.read()\n",
    "\n",
    "    soup = BeautifulSoup(contents,'html.parser')\n",
    "\n",
    "    ep_table = soup.find(name='table',class_='ep-table')\n",
    "    ep_table.find(name='tr',text=\"Air Date\")\n",
    "    ep_table = ep_table.find_all(name='tr')\n",
    "    for section in ep_table:\n",
    "        if section.find(name='th',text='Air Date'):\n",
    "            air_date = section.find(name='td').text\n",
    "\n",
    "\n",
    "\n",
    "    pi_table = soup.find(name='table',class_='pi-table')\n",
    "    pi_table = pi_table.find(name='tbody')\n",
    "\n",
    "    for section in pi_table.find_all(name='tr'):\n",
    "        if section.find(name='th').text == \"Business Pitch\":\n",
    "            business_pitch=section.find(name='td').text\n",
    "        \n",
    "        elif section.find(name='th').text == \"Entrepreneur/Founder\":\n",
    "            entrepreneur=section.find(name='td').text\n",
    "\n",
    "        elif section.find(name='th').text == \"Asked For\":\n",
    "            ask=section.find(name='td').text\n",
    "            ask_money = ask.split(\" for \")[0]\n",
    "            ask_equity = ask.split(\" for \")[1]\n",
    "\n",
    "        elif section.find(name='th').text == \"Deal\":\n",
    "            deal=section.find(name='td').text\n",
    "\n",
    "        elif section.find(name='th').text == \"Shark\":\n",
    "            shark=section.find(name='td').text\n",
    "\n",
    "    bi_table = soup.find(name='table',class_='bi-table')\n",
    "    bi_table = bi_table.find(name='tbody')\n",
    "\n",
    "    for section in bi_table.find_all(name='tr'):\n",
    "        if section.find(name='th').text == \"Business Status\":\n",
    "            business_status=section.find(name='td').text\n",
    "        \n",
    "        elif section.find(name='th').text == \"Estimated Valuation\":\n",
    "            valuation=section.find(name='td').text\n",
    "\n",
    "        elif section.find(name='th').text == \"Website\":\n",
    "            website=section.find(name='td').text\n",
    "\n",
    "    recap_summary = soup.find(name=\"ul\",class_=\"recap-summary\")\n",
    "    recap_summary = recap_summary.find_all(name='li')\n",
    "    summary = \"\"\n",
    "    for bullet_point in recap_summary:\n",
    "        try:\n",
    "            summary = f\"{summary}{bullet_point.find('span').get('class')[1]}{html.unescape(bullet_point.text)}\\n\"\n",
    "        except AttributeError:\n",
    "            summary = f\"{summary}{bullet_point.text}\\n\"\n",
    "\n",
    "\n",
    "    full_df_list.append((pitch.Season,pitch.Episode,pitch.Company,pitch.Link,pitch.Endpoint,pitch[\"Page Source\"],air_date, business_pitch, entrepreneur, ask_money, ask_equity, deal, shark, business_status, valuation, website, summary))\n",
    "\n",
    "\n",
    "full_df = pd.DataFrame(full_df_list, columns=['Season','Episode','Company','Link','Endpoint',\"Page Source\",'Air Date','Business Pitch','Entrepreneur','Ask Money','Ask Equity','Deal','Shark','Business Status','Valuation','Website','Summary'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jared",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
